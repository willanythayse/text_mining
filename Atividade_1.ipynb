{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Atividade_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willanythayse/text_mining_with_r/blob/master/Atividade_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "TzaMB5MgU-Xt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Library"
      ]
    },
    {
      "metadata": {
        "id": "IxZCl7V1VJ7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7f7eae18-24a5-4f00-adb6-bcaad239571e"
      },
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import os\n",
        "os.system(\"python -m spacy download pt\")\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk.probability import FreqDist"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SfK9yKJbXusC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Modelo"
      ]
    },
    {
      "metadata": {
        "id": "EzwAEOgXXw2G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oO_iqO1kX4h9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Variáveis de Entrada "
      ]
    },
    {
      "metadata": {
        "id": "JnVCK9hnX8N0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "122a4e2b-ca7d-4029-f472-211c5af1f8f1"
      },
      "cell_type": "code",
      "source": [
        "Text1 = \"Olha, lamentavelmente, a crise elétrica já dura uma década na Venezuela. Hugo Chávez decretou uma emergência elérica em 2009, resultado do que chamaram de uma crise gerada pela natureza. Naquele momento, foi o El Niño. Investiram US$ 100 bilhões (R$ 384,7 bilhões) no sistema elétrico venezuelano. Em 2013, o sistema elétrico foi militarizado. Agora, culparam uma iguana, que teria comido um cabo e produzido o apagão, na versão oficial.\"\n",
        "Text2 = \"Se a situação não fosse trágica na Venezuela, se não fosse lastimável e não agravasse a complexa crise humanitária que vive o país, eu daria risada. Mas não se pode rir quando morrem crianças, quando passamos seis dias sem poder trabalhar no país, quando isso impacta desta forma nosso cotidiano e a economia.\"\n",
        "\n",
        "#Para uso nlp\n",
        "#Text1 = nlp(\"Olha, lamentavelmente, a crise elétrica já dura uma década na Venezuela. Hugo Chávez decretou uma emergência elérica em 2009, resultado do que chamaram de uma crise gerada pela natureza. Naquele momento, foi o El Niño. Investiram US$ 100 bilhões (R$ 384,7 bilhões) no sistema elétrico venezuelano. Em 2013, o sistema elétrico foi militarizado. Agora, culparam uma iguana, que teria comido um cabo e produzido o apagão, na versão oficial.\")\n",
        "#Text2 = nlp(\"Se a situação não fosse trágica na Venezuela, se não fosse lastimável e não agravasse a complexa crise humanitária que vive o país, eu daria risada. Mas não se pode rir quando morrem crianças, quando passamos seis dias sem poder trabalhar no país, quando isso impacta desta forma nosso cotidiano e a economia.\")\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Olha, lamentavelmente, a crise elétrica já dura uma década na Venezuela.', 'Hugo Chávez decretou uma emergência elérica em 2009, resultado do que chamaram de uma crise gerada pela natureza.', 'Naquele momento, foi o El Niño.', 'Investiram US$ 100 bilhões (R$ 384,7 bilhões) no sistema elétrico venezuelano.', 'Em 2013, o sistema elétrico foi militarizado.', 'Agora, culparam uma iguana, que teria comido um cabo e produzido o apagão, na versão oficial.']\n",
            "['Se a situação não fosse trágica na Venezuela, se não fosse lastimável e não agravasse a complexa crise humanitária que vive o país, eu daria risada.', 'Mas não se pode rir quando morrem crianças, quando passamos seis dias sem poder trabalhar no país, quando isso impacta desta forma nosso cotidiano e a economia.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oDkbaMXhdK62",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tokenização"
      ]
    },
    {
      "metadata": {
        "id": "8vl_GIi1dKOa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4d353899-36f3-4345-96ff-1c2ca5c04f3f"
      },
      "cell_type": "code",
      "source": [
        "tokenized_text1=sent_tokenize(Text1)\n",
        "print(tokenized_text1)\n",
        "\n",
        "tokenized_text2=sent_tokenize(Text2)\n",
        "print(tokenized_text2)\n",
        "\n",
        "tokenized_word1=word_tokenize(Text1)\n",
        "print(tokenized_word1)\n",
        "\n",
        "tokenized_word2=word_tokenize(Text2)\n",
        "print(tokenized_word2)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Olha, lamentavelmente, a crise elétrica já dura uma década na Venezuela.', 'Hugo Chávez decretou uma emergência elérica em 2009, resultado do que chamaram de uma crise gerada pela natureza.', 'Naquele momento, foi o El Niño.', 'Investiram US$ 100 bilhões (R$ 384,7 bilhões) no sistema elétrico venezuelano.', 'Em 2013, o sistema elétrico foi militarizado.', 'Agora, culparam uma iguana, que teria comido um cabo e produzido o apagão, na versão oficial.']\n",
            "['Se a situação não fosse trágica na Venezuela, se não fosse lastimável e não agravasse a complexa crise humanitária que vive o país, eu daria risada.', 'Mas não se pode rir quando morrem crianças, quando passamos seis dias sem poder trabalhar no país, quando isso impacta desta forma nosso cotidiano e a economia.']\n",
            "['Olha', ',', 'lamentavelmente', ',', 'a', 'crise', 'elétrica', 'já', 'dura', 'uma', 'década', 'na', 'Venezuela', '.', 'Hugo', 'Chávez', 'decretou', 'uma', 'emergência', 'elérica', 'em', '2009', ',', 'resultado', 'do', 'que', 'chamaram', 'de', 'uma', 'crise', 'gerada', 'pela', 'natureza', '.', 'Naquele', 'momento', ',', 'foi', 'o', 'El', 'Niño', '.', 'Investiram', 'US', '$', '100', 'bilhões', '(', 'R', '$', '384,7', 'bilhões', ')', 'no', 'sistema', 'elétrico', 'venezuelano', '.', 'Em', '2013', ',', 'o', 'sistema', 'elétrico', 'foi', 'militarizado', '.', 'Agora', ',', 'culparam', 'uma', 'iguana', ',', 'que', 'teria', 'comido', 'um', 'cabo', 'e', 'produzido', 'o', 'apagão', ',', 'na', 'versão', 'oficial', '.']\n",
            "['Se', 'a', 'situação', 'não', 'fosse', 'trágica', 'na', 'Venezuela', ',', 'se', 'não', 'fosse', 'lastimável', 'e', 'não', 'agravasse', 'a', 'complexa', 'crise', 'humanitária', 'que', 'vive', 'o', 'país', ',', 'eu', 'daria', 'risada', '.', 'Mas', 'não', 'se', 'pode', 'rir', 'quando', 'morrem', 'crianças', ',', 'quando', 'passamos', 'seis', 'dias', 'sem', 'poder', 'trabalhar', 'no', 'país', ',', 'quando', 'isso', 'impacta', 'desta', 'forma', 'nosso', 'cotidiano', 'e', 'a', 'economia', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HX_FJef8ZJsn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Para uso nlp\n",
        "for token in Text1:\n",
        "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\".format(\n",
        "        token.text,\n",
        "        token.idx,\n",
        "        token.lemma_,\n",
        "        token.is_stop,\n",
        "        token.is_punct,\n",
        "        token.is_space,\n",
        "        token.pos_,\n",
        "        token.tag_\n",
        "    ))\n",
        "\n",
        "for token in Text2:\n",
        "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\".format(\n",
        "        token.text,\n",
        "        token.idx,\n",
        "        token.lemma_,\n",
        "        token.is_stop,\n",
        "        token.is_punct,\n",
        "        token.is_space,\n",
        "        token.pos_,\n",
        "        token.tag_\n",
        "    ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ac78F4uyZq91",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Para uso nlp\n",
        "\n",
        "for sent in Text1.sents:\n",
        "    print(sent)\n",
        "\n",
        "for sent in Text2.sents:\n",
        "    print(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IpyJ8FVoZ-XA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "6aa3f9c3-8a5f-46c9-a23a-70df22ac0adf"
      },
      "cell_type": "code",
      "source": [
        "#Para uso nlp\n",
        "new1 = [token.text.lower() for token in Text1 if not(token.is_stop or token.is_punct)]\n",
        "print(new1)\n",
        "\n",
        "new2 = [token.text.lower() for token in Text2 if not(token.is_stop or token.is_punct)]\n",
        "print(new2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-58ce7c0c31d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mText1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_punct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mText2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_punct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-58ce7c0c31d0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mText1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_punct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mText2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_punct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'is_stop'"
          ]
        }
      ]
    }
  ]
}